{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "A-first-look-at-deep-learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xpertdesh/ml-class21/blob/main/labs/A_first_look_at_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mKArb-b1_En"
      },
      "source": [
        "### Note:\n",
        "\n",
        "**First let's set the runtime to TPU (Tensor Processing Unit) -- click on 'runtime' in the menu above, select 'Change runtime type' and pick 'TPU'.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ii5clez0HmE"
      },
      "source": [
        "# A First Look at Deep Learning using Keras  \n",
        "\n",
        "This notebook is a remix of one by Francis Cholet (see the end of the notebook for more information)\n",
        "\n",
        "\n",
        "![](http://zacharski.org/files/courses/cs419/keras.jpg)\n",
        "\n",
        "It is intended to be a first quick hands-on introduction to deep learning using TensorFlow and Keras. \n",
        "\n",
        "\n",
        "### Brain engaged\n",
        "Throughout this notebook there are questions for you to answer. It is easy to go through a notebook without understanding---click, click, click through the cells. The questions are designed to help you pause and think.\n",
        "It is always a good idea to pause and think. Regardless of whether you are working through this notebook, or having tea with a friend, it is best to be fully present and in the moment and not have your brain wander all over the place. Regardless of whether you are working on this notebook or having tea with a friend, put away that cell phone and engage with what is in front of you.\n",
        "\n",
        "With that advice out of the way and \n",
        "before the hands-on, let's cover a few definitions.\n",
        "\n",
        "#### Tensor\n",
        "> In mathematics, a **tensor** is an algebraic object that describes a (multilinear) relationship between sets of algebraic objects related to a vector space. Objects that tensors may map between include vectors and scalars, and even other tensors. [Wikipedia](https://colab.research.google.com/drive/1BycU14ycvRTu0wM4OrK34qx8nK84r8Lj#scrollTo=2ii5clez0HmE)\n",
        "\n",
        "\n",
        "#### TensorFlow\n",
        "TensorFlow was developed by the Google Brain Team. It is an open source Tensor library used to develop deep learning models. Google uses it for translate, search, and gmail, among others. And a wide variety of other companies from AirBnb to Twitter use it as well. \n",
        "\n",
        "It isn't the only option to use. **Pytorch**, developed by Facebook's AI Research Lab, is another popular deep learning library. In fact, Tesla's AutoDrive software was built using PyTorch. \n",
        "\n",
        "#### Keras\n",
        "Keras is open source software that functions as an abstract interface to TensorFlow. \n",
        "\n",
        "My difficulty ranking of these (from easiest to hardest) is \n",
        "\n",
        "1. Keras\n",
        "2. PyTorch\n",
        "3. TensorFlow\n",
        "\n",
        "All have their strengths and it is difficult to recommend which one a beginner should start with. The excellent, free, Open.ai course uses PyTorch. However, in our exploration of deep learning we will start with Keras. In your path toward deepening your knowledge in machine learning you will likely encounter all three."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHO0x8YE0HmF"
      },
      "source": [
        "Let's import the Keras library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DS58igpC0HmG",
        "outputId": "d7778950-39fd-4e6e-d39c-e340fd80a42e"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noY1wNno0HmK"
      },
      "source": [
        "# A first look at a neural network\n",
        "\n",
        "\n",
        "![](https://raw.githubusercontent.com/zacharski/ml-class/master/labs/pics/mnist.jpg)\n",
        "\n",
        "Let's go back to the example of recognizing hand written digits. \n",
        "We are using the MNIST dataset (Modified National Institute of Standards) which is a dataset of 60,000 training instances and 10,000 testing instances of 28x28 grayscale images of the digits 0 through 9. This dataset was created in the 1980s as a testbed for various research groups. Back then it was considered a hard problem. Today it is considered the \"hello world\" equivalent in deep learning and you will see it again and again on your path learning about machine learning. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tUaQ5q20HmK"
      },
      "source": [
        "The MNIST dataset is so common that Keras knows how to download the data into a set of four Numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voWJ4eMm0HmL",
        "outputId": "db95f02c-b47a-4767-bb60-6859074a7c34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsarChQu0HmN"
      },
      "source": [
        "`train_images` and `train_labels` form the \"training set\", the data that the model will learn from. The model will then be tested on the \n",
        "\"test set\", `test_images` and `test_labels`. The Keras version of this dataset encodes the images as Numpy arrays, and the labels are simply an array of digits, ranging \n",
        "from 0 to 9. There is a one-to-one correspondence between the images and the labels.\n",
        "\n",
        "Let's have a look at the training data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5UJNpAs0HmN",
        "outputId": "ed1293d5-d00b-49b8-af1c-16333256f677"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQoTEY6o2a5H"
      },
      "source": [
        "That is not surprising---so 60,000 images that are a 28x28 array of pixel values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGoBVIWU0HmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a5375c-819a-41b5-938a-495c97cdfad7"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xrzLvCu0HmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f333068a-51ff-48d7-9086-6e7be317a662"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw4IhMIr0Hmm"
      },
      "source": [
        "# The data\n",
        "To get an idea of what the data looks like let's display a few images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "K4oH15sT0Hmm",
        "outputId": "90910032-18d7-4b9d-84da-5652a18b245b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def viewImage(x):\n",
        "    plt.figure(figsize=(2,2))\n",
        "    plt.imshow(x, interpolation='nearest', cmap='gray')\n",
        "    plt.show()\n",
        "    \n",
        "viewImage(test_images[0])\n",
        "viewImage(test_images[1])\n",
        "viewImage(test_images[2])\n",
        "viewImage(test_images[3])\n",
        "viewImage(test_images[4])\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ereJKgeH_-5f"
      },
      "source": [
        "and let's look at the associated labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8HKsdisAC_x",
        "outputId": "900c8b05-ca71-4eda-87dd-fb10c8e0c130"
      },
      "source": [
        "test_labels[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, 0, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_XKnAu30Hmp"
      },
      "source": [
        "Well, that is encouraging -- The images and the labels match!\n",
        "\n",
        "### Workflow\n",
        "\n",
        "\n",
        "Our workflow will be as follow: \n",
        "\n",
        "1. we will create a neural network containing a fully connected hidden layer.\n",
        "2. we will present our neural network with the training data, `train_images` and `train_labels`. The \n",
        "network will then learn to associate images and labels. \n",
        "3. we will ask the network to produce predictions for `test_images`\n",
        "4. we will verify if these predictions match the labels from `test_labels`.\n",
        "\n",
        "#### Let's build our network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I0sj6hW0Hmp"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouiEONIe0Hms"
      },
      "source": [
        "\n",
        "The core building block of neural networks is the \"layer\", a data-processing module which you can conceive as a \"filter\" for data. Some \n",
        "data comes in, and comes out in a more useful form. Precisely, layers extract _representations_ out of the data fed into them -- hopefully \n",
        "representations that are more meaningful for the problem at hand. Most of deep learning really consists of chaining together simple layers \n",
        "which will implement a form of progressive \"data distillation\". A deep learning model is like a sieve for data processing, made of a \n",
        "succession of increasingly refined data filters -- the \"layers\".\n",
        "\n",
        "Here our network consists of a sequence of two `Dense` layers, which are densely-connected (also called \"fully-connected\") neural layers. \n",
        "The second (and last) layer is a 10-way \"softmax\" layer, which means it will return an array of 10 probability scores (summing to 1). Each \n",
        "score will be the probability that the current digit image belongs to one of our 10 digit classes.\n",
        "\n",
        "\n",
        "### Explained yet again\n",
        "Okay, let's look at each of the above code lines\n",
        "\n",
        "     network = models.Sequential()\n",
        "     \n",
        "My English translation of this is \"We want a model with a linear (sequential) stack of layers.\"  The model initially has zero layers.\n",
        "\n",
        "Next we have...\n",
        "\n",
        "     network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "     \n",
        "Here we add a layer to the model. `Dense` means that every input node (since this is the first layer, this means every input feature) is connected to every node in this layer.  The `512` means how many node we want in this layer -- 512. `activation=relu` defines the activation function. We will talk about this later. Finally we define what the shape of the input is. Since every image is 28 x 28, our input shape is 28 * 28 or 784 (and yes, we could have written `input_shape=(784, )`.\n",
        "\n",
        "Next,\n",
        "\n",
        "     network.add(layers.Dense(10, activation='softmax'))\n",
        "     \n",
        "Here we add another layer. Again, `Dense` means that each node of the 512 nodes of the pervious layer are connected to the 10 of this layer. The `10` means there are 10 nodes. \n",
        "\n",
        "#### Compiling the model.\n",
        "To make our network ready for training, we need to pick three more things, as part of a compilation step:\n",
        "\n",
        "* An **optimizer**: this is the mechanism through which the network will update itself based on the data it sees and its loss function.\n",
        "* A **loss function**: this is how the network will be able to measure how good a job it is doing on its training data, and thus how it will be \n",
        "able to steer itself in the right direction.\n",
        "* **Metrics** to monitor during training and testing. Here we will only care about accuracy (the fraction of the images that were correctly \n",
        "classified).\n",
        "\n",
        "Keras makes this compilation step easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXUIZUwN0Hmt"
      },
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcclDPL10Hmu"
      },
      "source": [
        "\n",
        "Why did we select categorical crossentropy as the loss function? From the Tensorflow documentation:\n",
        "\n",
        "> Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided in a one_hot representation. If you want to provide labels as integers, please use SparseCategoricalCrossentropy loss. There should be # classes floating point values per feature.\n",
        "\n",
        "Note that the documentation says that we need to one_hot encode the labels. You probably already know this but that means if we are labeling pictures of dogs, cats, squirrel and moose and our test_labels look like\n",
        "\n",
        "picture | label\n",
        ":---:   | :---\n",
        "1.  | dog\n",
        "2. | dog\n",
        "3. | cat\n",
        "4. | squirel\n",
        "5. | cat\n",
        "6. | moose\n",
        "\n",
        "We will one_hot encode this resulting in \n",
        "\n",
        "\n",
        "picture | dog | cat | squirrel | moose\n",
        ":---: | :----: |:--: | :---: | :---:\n",
        " 1.     | 1 | 0 | 0 | 0\n",
        " 2. | 1 | 0| 0 | 0\n",
        " 3. | 0 | 1 | 0 | 0\n",
        " 4. | 0 | 0 | 1 | 0\n",
        " 5. | 0 | 1 |0 | 0\n",
        " 6. | 0|0|0|1\n",
        "\n",
        "And again, the `metrics=['accuracy']` line means that we are calculating the percentage of predicted values that match with actual values.\n",
        "\n",
        "\n",
        "### Preprocessing the data\n",
        "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in \n",
        "the `[0, 1]` interval. Previously, our training images for instance were stored in an array of shape `(60000, 28, 28)` of type `uint8` with \n",
        "values in the `[0, 255]` interval. We transform it into a `float32` array of shape `(60000, 28 * 28)` with values between 0 and 1.\n",
        "\n",
        "In other words, each image in our original data was a 28x28 array of integers ranging from 0 to 255. We are going to transform the integers 0-255 to a float between 0 and 1. In addition we are going to flatten each image array to look like\n",
        "\n",
        "```\n",
        "[0, 1, 2, 3, 4, 5 ... 784 ]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-tevXPN0Hmv"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZmD0beAJiMN",
        "outputId": "38a5a9b0-cadb-4e55-85dc-ec668ec9e904"
      },
      "source": [
        "test_images"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efw6Tx4x0Hmy"
      },
      "source": [
        "#### Here's a question:\n",
        "Why are we dividing each pixel by 255? What did the original number represent?\n",
        "\n",
        "#### Encode the labels\n",
        "We also need to categorically encode the labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBoQhwiX0Hmz"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNSszmzz0Hm1"
      },
      "source": [
        "### What does the first test label look like? (print it out)\n",
        "And what is this called?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6de8eFdF0Hm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71eadfd5-b70a-4809-ce99-25c5f633919f"
      },
      "source": [
        "# it's a 5\r\n",
        "train_labels[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3wWDY0g0Hm3"
      },
      "source": [
        "### Training our first deep learning model\n",
        "\n",
        "We are now ready to train our network, which, unsurprisingly, in Keras is done via a call to the `fit` method of the network: \n",
        "we \"fit\" the model to its training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JQ7pH630Hm4",
        "outputId": "bd86cbc0-0236-428d-a740-5f94faa1d7b7"
      },
      "source": [
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4339 - accuracy: 0.8736\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1127 - accuracy: 0.9666\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0688 - accuracy: 0.9791\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0510 - accuracy: 0.9848\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0378 - accuracy: 0.9887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde83365590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37PUt_b-0Hm7"
      },
      "source": [
        "Two quantities are being displayed during training: the \"loss\" of the network over the training data, and the accuracy of the network over \n",
        "the training data.\n",
        "\n",
        "We quickly reach an accuracy of 0.989 (i.e. 98.9%) on the training data. Now let's check that our model performs well on the test set too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig8FrFXQ0Hm8",
        "outputId": "215cefa3-1989-43ef-ec80-4d735ecc09be"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0746 - accuracy: 0.9784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6QizHgB0Hm-",
        "outputId": "83237778-416d-46a9-a78d-c814b226c512"
      },
      "source": [
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.9783999919891357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEzOBPol0HnA"
      },
      "source": [
        "\n",
        "Our test set accuracy turns out to be 97.8% -- that's quite a bit lower than the training set accuracy. \n",
        "This gap between training accuracy and test accuracy is an example of \"overfitting\", \n",
        "the fact that machine learning models tend to perform worse on new data than on their training data. \n",
        "\n",
        "\n",
        "### Accuracy with 7 epochs\n",
        "What is the accuracy on our test data if we use 7 epochs?  You will need to build, compile, and fit a new model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2awmR340HnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c09511-a085-4574-cb29-4070f78679f9"
      },
      "source": [
        "# build network\r\n",
        "network_7e = models.Sequential()\r\n",
        "network_7e.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\r\n",
        "network_7e.add(layers.Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "network_7e.compile(optimizer='rmsprop',\r\n",
        "                loss='categorical_crossentropy',\r\n",
        "                metrics=['accuracy'])\r\n",
        "\r\n",
        "network_7e.fit(train_images, train_labels, epochs=7, batch_size=128)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.4223 - accuracy: 0.8768\n",
            "Epoch 2/7\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.1115 - accuracy: 0.9674\n",
            "Epoch 3/7\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0679 - accuracy: 0.9796\n",
            "Epoch 4/7\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0462 - accuracy: 0.9870\n",
            "Epoch 5/7\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0362 - accuracy: 0.9887\n",
            "Epoch 6/7\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0261 - accuracy: 0.9920\n",
            "Epoch 7/7\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0195 - accuracy: 0.9945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde82af6690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVGGB3vdXJMr",
        "outputId": "ee31236f-e93b-4772-9f99-72b5400ba1e8"
      },
      "source": [
        "test_loss, test_acc = network_7e.evaluate(test_images, test_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0639 - accuracy: 0.9816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIPPdzcTXRQZ",
        "outputId": "e6d2a018-5c22-4483-d5fb-cf2ed01b1c47"
      },
      "source": [
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.9815999865531921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjZOO2O10HnD"
      },
      "source": [
        "### Accuracy without training\n",
        "What is the accuracy on our test data using our network before we do any training (before `fit`)? You will need to build, compile, and fit a new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CjGS-7LTo_L",
        "outputId": "394bd09f-fdac-4385-8288-2e97de864155"
      },
      "source": [
        "# build network\r\n",
        "notrain_network = models.Sequential()\r\n",
        "notrain_network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\r\n",
        "notrain_network.add(layers.Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "notrain_network.compile(optimizer='rmsprop',\r\n",
        "                loss='categorical_crossentropy',\r\n",
        "                metrics=['accuracy'])\r\n",
        "\r\n",
        "notrain_testloss, notrain_testacc = notrain_network.evaluate(test_images, test_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 2.3482 - accuracy: 0.1103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6mbph_sXl5s",
        "outputId": "28463ac4-291f-4757-e053-58e7901ad4b1"
      },
      "source": [
        "print('test_acc:', notrain_testacc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.11569999903440475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4qA1lPZ0HnG"
      },
      "source": [
        "### Training\n",
        "As you can see from your above experiment, before we fit the model the accuracy was not very good. Before training, the weight are set at random (not exactly, but let's keep it simple for now). \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![](http://zacharski.org/files/courses/cs419/deepLearning.png)\n",
        "\n",
        "When we were fitting the model:\n",
        "\n",
        "     network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "    \n",
        "we processed 128 images at a time (this is called batch_size). Everytime we processed the images in that batch we calculated the loss and adjusted the weights to improve the network's  performance. Each time we go through the entire dataset we call it an epoch. So in our initial training, we went through the dataset 5 times.  Once we have gone through the data 5 times we stop and now we have a trained neural network. 'Trained' simply means that we have a network with the weight adjusted to reduce loss.\n",
        "\n",
        "#### Epochs \n",
        "Again, epochs are how many times we go through the training data. You may wonder, are more epochs always better. Stop for a moment and ponder this. \n",
        "\n",
        "* .\n",
        "* .\n",
        "* .\n",
        "* .\n",
        "If you need a clue let me mention bias and variance. \n",
        "\n",
        "In the next notebook we will be displaying both the accuracy on the training data and the accuracy on the validation error.  If at some point you see the training data accuracy still going gradually down, but the validation error going up. You may be overfitting your data.\n",
        "\n",
        "\n",
        "# You Try  - Fashion.\n",
        "\n",
        "### finally some xp\n",
        "\n",
        "As a small first step try out the FashionMNIST dataset that we've seen before.\n",
        "\n",
        "![](http://zacharski.org/files/courses/cs419/clothes-sprite.png)\n",
        "![](http://zacharski.org/files/courses/cs419/clothing.gif)\n",
        "\n",
        "\n",
        "The dataset consists of small 28x28 grayscale image icons of different articles of clothing. There are 60,000 images in the training set and 10,000 in the test set. Each image has an associated label from a list of 10:\n",
        "\n",
        "\n",
        "| Label | Description |\n",
        "| --- | --- |\n",
        "| 0 | T-shirt/top |\n",
        "| 1 | Trouser |\n",
        "| 2 | Pullover |\n",
        "| 3 | Dress |\n",
        "| 4 | Coat |\n",
        "| 5 | Sandal |\n",
        "| 6 | Shirt |\n",
        "| 7 | Sneaker |\n",
        "| 8 | Bag |\n",
        "| 9 | Ankle boot |\n",
        "\n",
        "\n",
        "\n",
        "#### The files\n",
        "\n",
        "* Training set: [clothes_train.csv](http://zacharski.org/files/courses/cs419/clothes_train.csv)\n",
        "* Test set: [clothing_test.csv](http://zacharski.org/files/courses/cs419/cTest.csv) Note: Don't use the test set for training.\n",
        "\n",
        "Can you create a network with one hidden layer similar to the example above and train it?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGQ4dIqEpIZ0"
      },
      "source": [
        "import pandas as pd\r\n",
        "clothes_train = pd.read_csv('http://zacharski.org/files/courses/cs419/clothes_train.csv')\r\n",
        "clothes_test = pd.read_csv('http://zacharski.org/files/courses/cs419/cTest.csv')\r\n",
        "\r\n",
        "# split up data\r\n",
        "clothes_train_features = clothes_train.drop('label', axis=1)\r\n",
        "clothes_test_features = clothes_test.drop('label', axis=1)\r\n",
        "clothes_train_labels = clothes_train['label']\r\n",
        "clothes_test_labels = clothes_test['label']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKQ71epRsozd"
      },
      "source": [
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "# create network and add layers\r\n",
        "clothes_network = models.Sequential()\r\n",
        "clothes_network.add(layers.Dense(512, activation='relu', input_shape=(784,)))\r\n",
        "clothes_network.add(layers.Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "# compile the network\r\n",
        "clothes_network.compile(optimizer='rmsprop',\r\n",
        "                loss='categorical_crossentropy',\r\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOf3VpM2stlE"
      },
      "source": [
        "# hot-encode the features set to get an interval\r\n",
        "# between [0, 1]\r\n",
        "clothes_train_features = clothes_train_features.astype('float32') / 255\r\n",
        "clothes_test_features = clothes_test_features.astype('float32') / 255\r\n",
        "\r\n",
        "# we also need to hot-encode the labels\r\n",
        "from keras.utils import to_categorical\r\n",
        "clothes_train_labels = to_categorical(clothes_train_labels)\r\n",
        "clothes_test_labels = to_categorical(clothes_test_labels)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DZJmQ-g0HnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1809b39-1d35-4fa7-e46a-d3682bf8bc86"
      },
      "source": [
        "clothes_network.fit(clothes_train_features, clothes_train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7631 - accuracy: 0.7380\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.3961 - accuracy: 0.8556\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3492 - accuracy: 0.8723\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.3145 - accuracy: 0.8844\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2925 - accuracy: 0.8919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde7f1dd090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgnlMXV90HnI"
      },
      "source": [
        "### What is its accuracy on the test data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR_lX8i90HnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7266e80f-0348-4712-fcaa-fb3f419a6eb4"
      },
      "source": [
        "test_loss, test_acc = clothes_network.evaluate(clothes_test_features, clothes_test_labels)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.8834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKf9vjLwV8xy",
        "outputId": "41be6134-eed5-4308-ab9c-5744f7e4d571"
      },
      "source": [
        "print('test_acc:', test_acc)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc: 0.883400022983551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY3fZL-l0HnL"
      },
      "source": [
        "### Q8 a two hidden layer network in Keras.\n",
        "Can you construct and train a new network that has two hidden layers \n",
        "(as before, the first layer can have 512 neurons - the second should have 256)? What is its accuracy on the test data? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9v0vPLzSLgu"
      },
      "source": [
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "# create network and add layers\r\n",
        "clothes_network = models.Sequential()\r\n",
        "clothes_network.add(layers.Dense(512, activation='relu', input_shape=(784,)))\r\n",
        "clothes_network.add(layers.Dense(256, activation='relu'))\r\n",
        "clothes_network.add(layers.Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "# compile the network\r\n",
        "clothes_network.compile(optimizer='rmsprop',\r\n",
        "                loss='categorical_crossentropy',\r\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f8lX1qFUChp",
        "outputId": "eb483005-6592-402b-e1ee-30adc1fe8e47"
      },
      "source": [
        "clothes_network.fit(clothes_train_features, clothes_train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.7250 - accuracy: 0.7358\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.3816 - accuracy: 0.8577\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.3385 - accuracy: 0.8747\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.3098 - accuracy: 0.8863\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 6s 14ms/step - loss: 0.2976 - accuracy: 0.8891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde7e50ee50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp-WJ3DfWh4f",
        "outputId": "84c84c44-3852-4101-bf8f-95f9f14af621"
      },
      "source": [
        "test_loss, test_acc = clothes_network.evaluate(clothes_test_features, clothes_test_labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6z8du_mWp9G",
        "outputId": "cf475e65-837e-44b4-d684-506d4c05b988"
      },
      "source": [
        "print('test_acc: ', test_acc)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_acc:  0.8859999775886536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8ll6Pz00HnO"
      },
      "source": [
        "# Volcanoes on Venus \n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/1/16/Maat_Mons_on_Venus.jpg)\n",
        "\n",
        "\n",
        "### First, no one has been to Venus\n",
        "I felt I needed to say that upfront because we don't really know if there are volcanoes on Venus. An analysis of the data by experts is not 100% accurate so the labels are the experts best guess.\n",
        "\n",
        "The images are from NASA's Magellan spacecraft which was launched on May 4, 1989 and made it to Venus on August 10, 1990. Magellan mapped the surface of Venus using synthetic aperture radar. Some images have black blocks in them caused by either problems with Magellan or with communication back to earth. \n",
        "\n",
        "### The data\n",
        "The images are 110x110 grayscale pixels. The value of each pixel ranges from 0 to 255. Your task it to build a classifier that will predict whether a volcano is present in the image or not.\n",
        "\n",
        "#### The files\n",
        "\n",
        "* Training images: [volcanoes_train_images.csv](http://zacharski.org/files/courses/cs419/volcanoes_train_images.csv)\n",
        "* Training labels: [volcanoes_train_labels.csv](http://zacharski.org/files/courses/cs419/volcanoes_train_labels.csv) \n",
        "* Testing images: [volcanoes_test_images.csv](http://zacharski.org/files/courses/cs419/volcanoes_test_images.csv)\n",
        "* Testing labels: [volcanoes_test_labels.csv](http://zacharski.org/files/courses/cs419/volcanoes_test_labels.csv) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Tasks\n",
        "\n",
        "There are 5 tasks\n",
        "\n",
        "1. A simple task: Can you display a few of the images from the dataset?\n",
        "2. Build a model with one hidden layer. Train it for 2 epochs. What is it's accuracy?\n",
        "3. Build a model with one hidden layer. Train it for 10 epochs. What is it's accuracy? \n",
        "4. Does increasing the epochs beyond 10 improve accuracy?\n",
        "5. Build a model with 2 hidden layers and test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlZ70ggnlrmV"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "train_images = pd.read_csv('http://zacharski.org/files/courses/cs419/volcanoes_train_images.csv')#.to_numpy()\r\n",
        "train_labels = pd.read_csv('http://zacharski.org/files/courses/cs419/volcanoes_train_labels.csv')\r\n",
        "train_labels.drop(train_labels.tail(1).index, inplace=True)\r\n",
        "test_images = pd.read_csv('http://zacharski.org/files/courses/cs419/volcanoes_test_images.csv')#.to_numpy()\r\n",
        "test_labels = pd.read_csv('http://zacharski.org/files/courses/cs419/volcanoes_test_labels.csv')\r\n",
        "test_labels.drop(test_labels.tail(1).index, inplace=True)\r\n",
        "\r\n",
        "\r\n",
        "# drop unnecessary columns for labels \r\n",
        "train_labels = train_labels['Volcano?']\r\n",
        "test_labels = test_labels['Volcano?']\r\n",
        "\r\n",
        "#train_labels = train_labels.to_numpy()\r\n",
        "#test_labels = test_labels.to_numpy()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVql1pTMmj8A",
        "outputId": "16cf97c2-8e11-4079-87cc-9ba67abd16ed"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2733, 12100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPxAGXa6ljap"
      },
      "source": [
        "# I tried many different ways: pandas Df, numpy array, different dimensions,\r\n",
        "# different ways to allocate the rows, and couldn't figure it out\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "def viewImage(x):\r\n",
        "    plt.figure(figsize=(2,2))\r\n",
        "    plt.imshow(x, interpolation='nearest', cmap='copper')\r\n",
        "    plt.show()\r\n",
        "    \r\n",
        "viewImage(test_images.iloc[0])\r\n",
        "viewImage(test_images.iloc[1])\r\n",
        "viewImage(test_images.iloc[2])\r\n",
        "viewImage(test_images.iloc[3])\r\n",
        "viewImage(test_images.iloc[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZFUG8Fx0HnO",
        "outputId": "1383a64b-9168-450d-c868-d1ac0bd09a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Model with one hidden layer and 2 epochs\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "# create network and add layers\r\n",
        "network = models.Sequential()\r\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(110*110,)))\r\n",
        "network.add(layers.Dense(2, activation='softmax'))\r\n",
        "\r\n",
        "# compile the network\r\n",
        "network.compile(optimizer='rmsprop',\r\n",
        "                loss='categorical_crossentropy',\r\n",
        "                metrics=['accuracy'])\r\n",
        "\r\n",
        "# hot-encode the features set to get an interval\r\n",
        "# between [0, 1]\r\n",
        "train_images = train_images.astype('float32') / 255\r\n",
        "test_images = test_images.astype('float32') / 255\r\n",
        "\r\n",
        "# we also need to hot-encode the labels\r\n",
        "from keras.utils import to_categorical\r\n",
        "train_labels = to_categorical(train_labels)\r\n",
        "test_labels = to_categorical(test_labels)\r\n",
        "\r\n",
        "network.fit(train_images, train_labels, epochs=2, batch_size=128)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "55/55 [==============================] - 7s 107ms/step - loss: 8.3490 - accuracy: 0.7536\n",
            "Epoch 2/2\n",
            "55/55 [==============================] - 6s 108ms/step - loss: 3.2425 - accuracy: 0.7737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde6daa8490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUKtWktNwwsa",
        "outputId": "c2b5f9cb-39b0-4e3a-d9a7-b504217769ba"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - 1s 13ms/step - loss: 3.4313 - accuracy: 0.8408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvNZGhUEyCpK",
        "outputId": "c47fd29c-c289-4d02-e6c9-704dafdc274b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Model with one hidden layer and 10 epochs\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "# create network and add layers\r\n",
        "network = models.Sequential()\r\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(110*110,)))\r\n",
        "network.add(layers.Dense(2, activation='softmax'))\r\n",
        "\r\n",
        "# compile the network\r\n",
        "network.compile(optimizer='rmsprop',\r\n",
        "                loss='categorical_crossentropy',\r\n",
        "                metrics=['accuracy'])\r\n",
        "\r\n",
        "network.fit(train_images, train_labels, epochs=10, batch_size=128)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "55/55 [==============================] - 6s 108ms/step - loss: 7.8517 - accuracy: 0.7399\n",
            "Epoch 2/10\n",
            "55/55 [==============================] - 6s 107ms/step - loss: 1.8407 - accuracy: 0.7753\n",
            "Epoch 3/10\n",
            "55/55 [==============================] - 6s 108ms/step - loss: 1.1173 - accuracy: 0.7496\n",
            "Epoch 4/10\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 0.8539 - accuracy: 0.7871\n",
            "Epoch 5/10\n",
            "55/55 [==============================] - 6s 107ms/step - loss: 0.9580 - accuracy: 0.8138\n",
            "Epoch 6/10\n",
            "55/55 [==============================] - 6s 107ms/step - loss: 0.6861 - accuracy: 0.8289\n",
            "Epoch 7/10\n",
            "55/55 [==============================] - 6s 107ms/step - loss: 0.7231 - accuracy: 0.7883\n",
            "Epoch 8/10\n",
            "55/55 [==============================] - 6s 107ms/step - loss: 0.6050 - accuracy: 0.8109\n",
            "Epoch 9/10\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 0.4945 - accuracy: 0.8375\n",
            "Epoch 10/10\n",
            "55/55 [==============================] - 6s 106ms/step - loss: 0.5007 - accuracy: 0.8441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde6f8c92d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu0CWQxHy2KI",
        "outputId": "9296be40-9c93-4015-833e-06b0c277cbe8"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - 1s 14ms/step - loss: 0.5566 - accuracy: 0.8401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkRS3iUHzGVk",
        "outputId": "8c1565ff-6b46-48ea-c65f-543344068d7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Model with two hidden layers and 15 epochs\r\n",
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "# create network and add layers\r\n",
        "network = models.Sequential()\r\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(110*110,)))\r\n",
        "network.add(layers.Dense(256, activation='relu'))\r\n",
        "network.add(layers.Dense(2, activation='softmax'))\r\n",
        "\r\n",
        "# compile the network\r\n",
        "network.compile(optimizer='rmsprop',\r\n",
        "                loss='categorical_crossentropy',\r\n",
        "                metrics=['accuracy'])\r\n",
        "\r\n",
        "network.fit(train_images, train_labels, epochs=15, batch_size=128)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "55/55 [==============================] - 6s 109ms/step - loss: 5.9943 - accuracy: 0.7319\n",
            "Epoch 2/15\n",
            "55/55 [==============================] - 6s 109ms/step - loss: 0.7097 - accuracy: 0.7756\n",
            "Epoch 3/15\n",
            "55/55 [==============================] - 6s 109ms/step - loss: 0.4819 - accuracy: 0.8316\n",
            "Epoch 4/15\n",
            "55/55 [==============================] - 6s 111ms/step - loss: 0.4900 - accuracy: 0.8514\n",
            "Epoch 5/15\n",
            "55/55 [==============================] - 6s 110ms/step - loss: 0.4349 - accuracy: 0.8590\n",
            "Epoch 6/15\n",
            "55/55 [==============================] - 6s 110ms/step - loss: 0.4441 - accuracy: 0.8561\n",
            "Epoch 7/15\n",
            "55/55 [==============================] - 6s 110ms/step - loss: 0.4188 - accuracy: 0.8587\n",
            "Epoch 8/15\n",
            "55/55 [==============================] - 6s 110ms/step - loss: 0.4727 - accuracy: 0.8493\n",
            "Epoch 9/15\n",
            "55/55 [==============================] - 6s 111ms/step - loss: 0.4162 - accuracy: 0.8606\n",
            "Epoch 10/15\n",
            "55/55 [==============================] - 6s 111ms/step - loss: 0.4251 - accuracy: 0.8588\n",
            "Epoch 11/15\n",
            "55/55 [==============================] - 6s 110ms/step - loss: 0.4236 - accuracy: 0.8569\n",
            "Epoch 12/15\n",
            "55/55 [==============================] - 6s 110ms/step - loss: 0.4142 - accuracy: 0.8605\n",
            "Epoch 13/15\n",
            "55/55 [==============================] - 6s 109ms/step - loss: 0.4263 - accuracy: 0.8577\n",
            "Epoch 14/15\n",
            "55/55 [==============================] - 6s 114ms/step - loss: 0.4306 - accuracy: 0.8552\n",
            "Epoch 15/15\n",
            "55/55 [==============================] - 6s 116ms/step - loss: 0.4242 - accuracy: 0.8558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde6d953410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPUWhGp4zsD6",
        "outputId": "7e5ea112-8220-40c5-bef6-56b3840ec202"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86/86 [==============================] - 1s 14ms/step - loss: 0.4811 - accuracy: 0.8397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HeR6LQU0M95"
      },
      "source": [
        "1. A simple task: Can you display a few of the images from the dataset?\r\n",
        "Didn't seem to work as I explained in the comments of the code\r\n",
        "2. Build a model with one hidden layer. Train it for 2 epochs. What is it's accuracy?  84.08%\r\n",
        "3. Build a model with one hidden layer. Train it for 10 epochs. What is it's accuracy?  84.01%\r\n",
        "4. Does increasing the epochs beyond 10 improve accuracy?\r\n",
        "Not at all, it plateaus. It doesn't go beyond 84%\r\n",
        "5. Build a model with 2 hidden layers and test: \r\n",
        "I tested with different epochs and still had no major improvement\r\n",
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oPtUCBi0HnU"
      },
      "source": [
        "#### Remix\n",
        "Remix by Ron Zacharski. Orginal Python notebook by Franois Chollet\n",
        "\n",
        "### MIT License\n",
        "\n",
        "Copyright (c) 2017 Franois Chollet\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}